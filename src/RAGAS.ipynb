{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4547909de4434d80ac068c8973fd4eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_116a0920afd24dbdb8e66a5c6842571e",
              "IPY_MODEL_28879eb7bc3b41da8aa63c7f4b8e780f",
              "IPY_MODEL_5f31114b9d23448da551f5961aa29692"
            ],
            "layout": "IPY_MODEL_3d3ab4dc86904dd5bdde00221393e73b"
          }
        },
        "116a0920afd24dbdb8e66a5c6842571e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31415c3f6eac4536a77eea06c1ec44ca",
            "placeholder": "​",
            "style": "IPY_MODEL_5f8d3a92c38d4e31b85819dc84220154",
            "value": "Loading weights: 100%"
          }
        },
        "28879eb7bc3b41da8aa63c7f4b8e780f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4e9e5322a2349e289cb4cf6a67efefc",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_152eebad821e4cb2aa8642e4f612d912",
            "value": 199
          }
        },
        "5f31114b9d23448da551f5961aa29692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6611b52171c41a1b832e86e9f1872a5",
            "placeholder": "​",
            "style": "IPY_MODEL_126917ce6d364a81887d8cd76cd246e8",
            "value": " 199/199 [00:00&lt;00:00, 392.81it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "3d3ab4dc86904dd5bdde00221393e73b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31415c3f6eac4536a77eea06c1ec44ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f8d3a92c38d4e31b85819dc84220154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4e9e5322a2349e289cb4cf6a67efefc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "152eebad821e4cb2aa8642e4f612d912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6611b52171c41a1b832e86e9f1872a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "126917ce6d364a81887d8cd76cd246e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import subprocess, sys\n",
        "\n",
        "packages = [\n",
        "    \"langchain-ollama\",\n",
        "    \"langchain-core\",\n",
        "    \"sentence-transformers\",\n",
        "    \"scikit-learn\",\n",
        "    \"pandas\",\n",
        "    \"openpyxl\",\n",
        "    \"tqdm\",\n",
        "]\n",
        "for pkg in packages:\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"], check=True)\n",
        "\n",
        "print(\"Đã cài đặt tất cả thư viện\")\n",
        "\n",
        "import subprocess, time, os, threading"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzHaWfANlq1b",
        "outputId": "3c9fffc2-c80f-4538-bc44-e9c7544e1b63"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã cài đặt tất cả thư viện\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lON4WrQNisKx",
        "outputId": "fde85f61-ff9f-4146-a706-9178ecb0ab74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Đang cài đặt zstd...\n",
            "zstd đã cài đặt xong.\n",
            "Đang cài Ollama...\n",
            "Ollama đã cài xong\n",
            "Ollama executable đã được tìm thấy.\n",
            " Khởi động Ollama server...\n",
            "Ollama server đang chạy\n",
            "\n",
            " Đang pull model qwen2.5:7b (có thể mất vài phút)...\n",
            "Model qwen2.5:7b sẵn sàng!\n"
          ]
        }
      ],
      "source": [
        "# Install zstd, a dependency required by Ollama's install script\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\" Đang cài đặt zstd...\")\n",
        "install_zstd_proc = subprocess.run([\"apt-get\", \"update\"], capture_output=True, text=True)\n",
        "if install_zstd_proc.returncode != 0:\n",
        "    print(f\"Lỗi khi cập nhật apt: {install_zstd_proc.stderr}\")\n",
        "\n",
        "install_zstd_proc = subprocess.run([\"apt-get\", \"install\", \"-y\", \"zstd\"], capture_output=True, text=True)\n",
        "if install_zstd_proc.returncode != 0:\n",
        "    print(f\"Lỗi khi cài đặt zstd: {install_zstd_proc.stderr}\")\n",
        "else:\n",
        "    print(\"zstd đã cài đặt xong.\")\n",
        "\n",
        "def install_and_start_ollama():\n",
        "    print(\"Đang cài Ollama...\")\n",
        "    # Using Popen to capture stdout and stderr separately for clarity\n",
        "    install_proc = subprocess.Popen(\n",
        "        \"curl -fsSL https://ollama.com/install.sh | sh\",\n",
        "        shell=True,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True\n",
        "    )\n",
        "    stdout, stderr = install_proc.communicate()\n",
        "\n",
        "    if install_proc.returncode != 0:\n",
        "        print(f\"Lỗi cài Ollama (mã lỗi: {install_proc.returncode}).\")\n",
        "        if stdout: print(f\"Standard Output:\\n{stdout}\")\n",
        "        if stderr: print(f\"Standard Error:\\n{stderr}\")\n",
        "        return False\n",
        "    print(\"Ollama đã cài xong\")\n",
        "\n",
        "    # Add /usr/local/bin to PATH if not already present\n",
        "    if \"/usr/local/bin\" not in os.environ[\"PATH\"]:\n",
        "        os.environ[\"PATH\"] += \":/usr/local/bin\"\n",
        "        print(\"Đã thêm /usr/local/bin vào PATH.\")\n",
        "\n",
        "    # Verify ollama executable now exists in PATH\n",
        "    try:\n",
        "        subprocess.run([\"ollama\", \"--version\"], check=True, capture_output=True, text=True)\n",
        "        print(\"Ollama executable đã được tìm thấy.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Lỗi: Ollama executable vẫn không tìm thấy sau cài đặt. PATH hiện tại: {os.environ['PATH']}\")\n",
        "        return False\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Lỗi khi kiểm tra phiên bản Ollama: {e.stderr}\")\n",
        "        return False\n",
        "\n",
        "    # Khởi động Ollama server trong background\n",
        "    print(\" Khởi động Ollama server...\")\n",
        "    # Use Popen and check=False as it's a background process\n",
        "    server_proc = subprocess.Popen(\n",
        "        [\"ollama\", \"serve\"], # Should find 'ollama' now via updated PATH\n",
        "        stdout=subprocess.DEVNULL,\n",
        "        stderr=subprocess.DEVNULL\n",
        "    )\n",
        "    time.sleep(5)  # Chờ server khởi động\n",
        "\n",
        "    # Kiểm tra server\n",
        "    check_proc = subprocess.run(\n",
        "        [\"ollama\", \"list\"], # Should find 'ollama' now via updated PATH\n",
        "        capture_output=True, text=True\n",
        "    )\n",
        "    if check_proc.returncode == 0:\n",
        "        print(\"Ollama server đang chạy\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"Ollama server chưa sẵn sàng, chờ thêm... (mã lỗi: {check_proc.returncode})\")\n",
        "        if check_proc.stdout: print(f\"Server check stdout:\\n{check_proc.stdout}\")\n",
        "        if check_proc.stderr: print(f\"Server check stderr:\\n{check_proc.stderr}\")\n",
        "        time.sleep(5) # Wait a bit more\n",
        "        check_proc = subprocess.run(\n",
        "            [\"ollama\", \"list\"],\n",
        "            capture_output=True, text=True\n",
        "        )\n",
        "        if check_proc.returncode == 0:\n",
        "            print(\"Ollama server đang chạy sau khi chờ thêm\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"Ollama server không khởi động được sau khi chờ (mã lỗi: {check_proc.returncode}).\")\n",
        "            if check_proc.stdout: print(f\"Final server check stdout:\\n{check_proc.stdout}\")\n",
        "            if check_proc.stderr: print(f\"Final server check stderr:\\n{check_proc.stderr}\")\n",
        "            return False\n",
        "\n",
        "# ── Chọn model ──────────────────────────────────────────────\n",
        "# Gợi ý theo VRAM:\n",
        "#   qwen2.5:7b   → ~6GB VRAM  (T4 free)  — tốt nhất cho tiếng Việt\n",
        "#   llama3.2:3b  → ~3GB VRAM  (T4 free)  — nhanh hơn\n",
        "#   qwen2.5:14b  → ~12GB VRAM (Colab Pro) — chất lượng cao nhất\n",
        "\n",
        "OLLAMA_MODEL = \"qwen2.5:7b\"   # ← Đổi model tại đây nếu cần\n",
        "\n",
        "# Check the return value of install_and_start_ollama()\n",
        "if install_and_start_ollama():\n",
        "    print(f\"\\n Đang pull model {OLLAMA_MODEL} (có thể mất vài phút)...\")\n",
        "    pull_result = subprocess.run(\n",
        "        [\"ollama\", \"pull\", OLLAMA_MODEL],\n",
        "        capture_output=True, text=True\n",
        "    )\n",
        "    if pull_result.returncode == 0:\n",
        "        print(f\"Model {OLLAMA_MODEL} sẵn sàng!\")\n",
        "    else:\n",
        "        print(f\"Lỗi pull model: {pull_result.returncode}\")\n",
        "        print(\"Standard Output:\")\n",
        "        print(pull_result.stdout)\n",
        "        print(\"Standard Error:\")\n",
        "        print(pull_result.stderr)\n",
        "else:\n",
        "    print(\"Dừng thực thi do lỗi cài đặt/khởi động Ollama.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files as colab_files\n",
        "import json\n",
        "\n",
        "# Upload ragas_dataset.json từ máy lên Colab\n",
        "print(\"Hãy upload file ragas_dataset.json:\")\n",
        "uploaded = colab_files.upload()\n",
        "\n",
        "# Đọc dataset\n",
        "dataset_filename = list(uploaded.keys())[0]\n",
        "with open(dataset_filename, encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "samples = data.get(\"samples\", data) if isinstance(data, dict) else data\n",
        "print(f\"\\nĐã load {len(samples)} samples từ '{dataset_filename}'\")\n",
        "print(f\"   Ví dụ câu hỏi đầu: {samples[0]['question'][:60]}...\")\n",
        "\n",
        "\n",
        "LIMIT = None   # ← Đổi thành 10, 20,... nếu muốn test nhanh\n",
        "\n",
        "# ── Delay giữa các LLM calls (giây) ─────────────────────────\n",
        "CALL_DELAY = 0.3   # Local model không bị rate limit → delay nhỏ\n",
        "\n",
        "# ── Output ───────────────────────────────────────────────────\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/KLTN/ragas_output\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Model       : {OLLAMA_MODEL}\")\n",
        "print(f\"Samples     : {LIMIT or len(samples)} / {len(samples)}\")\n",
        "print(f\"Output dir  : {OUTPUT_DIR}\")\n",
        "\n",
        "from langchain_ollama import ChatOllama\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print(f\" Kết nối Ollama model: {OLLAMA_MODEL}\")\n",
        "llm = ChatOllama(model=OLLAMA_MODEL, temperature=0)\n",
        "\n",
        "# Test nhanh\n",
        "test_response = llm.invoke(\"Trả lời chỉ YES hoặc NO: Mặt trời mọc ở phía Đông?\").content\n",
        "print(f\"   Test LLM: '{test_response.strip()[:30]}' ✅\")\n",
        "\n",
        "print(\"\\n Đang tải embedding model...\")\n",
        "embed_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "print(\"Embedding model sẵn sàng\")\n",
        "\n",
        "import re, time\n",
        "\n",
        "def llm_call(prompt: str) -> str:\n",
        "    \"\"\"Gọi LLM local, không cần retry vì không có rate limit.\"\"\"\n",
        "    try:\n",
        "        return llm.invoke(prompt).content.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"        LLM error: {e}\")\n",
        "        return \"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435,
          "referenced_widgets": [
            "4547909de4434d80ac068c8973fd4eaf",
            "116a0920afd24dbdb8e66a5c6842571e",
            "28879eb7bc3b41da8aa63c7f4b8e780f",
            "5f31114b9d23448da551f5961aa29692",
            "3d3ab4dc86904dd5bdde00221393e73b",
            "31415c3f6eac4536a77eea06c1ec44ca",
            "5f8d3a92c38d4e31b85819dc84220154",
            "c4e9e5322a2349e289cb4cf6a67efefc",
            "152eebad821e4cb2aa8642e4f612d912",
            "a6611b52171c41a1b832e86e9f1872a5",
            "126917ce6d364a81887d8cd76cd246e8"
          ]
        },
        "id": "1JL8INA4mbiq",
        "outputId": "e771e684-50ca-44d1-aa3f-017abd967862"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hãy upload file ragas_dataset.json:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7d294c74-efe5-4bb6-8b4e-8ba61962f7f5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7d294c74-efe5-4bb6-8b4e-8ba61962f7f5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ragas_dataset.json to ragas_dataset (2).json\n",
            "\n",
            "Đã load 100 samples từ 'ragas_dataset (2).json'\n",
            "   Ví dụ câu hỏi đầu: Nếu em từng bị cảnh cáo học vụ ở học kỳ trước nhưng học kỳ n...\n",
            "Model       : qwen2.5:7b\n",
            "Samples     : 100 / 100\n",
            "Output dir  : /content/drive/MyDrive/KLTN/ragas_output\n",
            " Kết nối Ollama model: qwen2.5:7b\n",
            "   Test LLM: 'YES' ✅\n",
            "\n",
            " Đang tải embedding model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4547909de4434d80ac068c8973fd4eaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding model sẵn sàng\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ── METRIC 1: FAITHFULNESS ──────────────────────────────────\n",
        "def _extract_claims(answer: str) -> list:\n",
        "    prompt = f\"\"\"Phân tích câu trả lời sau và liệt kê TẤT CẢ các mệnh đề có trong đó.\n",
        "Mỗi mệnh đề là một thông tin/sự kiện cụ thể, không thể chia nhỏ hơn.\n",
        "\n",
        "Câu trả lời:\n",
        "{answer}\n",
        "\n",
        "Liệt kê các mệnh đề, mỗi mệnh đề bắt đầu bằng \"- \":\"\"\"\n",
        "    response = llm_call(prompt)\n",
        "    claims = [l.lstrip(\"- \").strip() for l in response.split(\"\\n\")\n",
        "              if l.strip().startswith(\"-\") and len(l.strip()) > 2]\n",
        "    return claims if claims else [answer]\n",
        "\n",
        "\n",
        "def _verify_claim(claim: str, context: str) -> bool:\n",
        "    prompt = f\"\"\"Context:\n",
        "{context[:2500]}\n",
        "\n",
        "Mệnh đề: {claim}\n",
        "\n",
        "Mệnh đề này có thể được suy ra từ context không?\n",
        "Trả lời CHỈ: YES hoặc NO\"\"\"\n",
        "    return \"YES\" in llm_call(prompt).upper()\n",
        "\n",
        "\n",
        "def faithfulness(answer: str, contexts: list) -> float:\n",
        "    if not answer or not contexts:\n",
        "        return 0.0\n",
        "    ctx = \"\\n---\\n\".join(contexts)\n",
        "    claims = _extract_claims(answer)\n",
        "    supported = sum(_verify_claim(c, ctx) for c in claims)\n",
        "    score = supported / len(claims)\n",
        "    print(f\"      Faithfulness: {supported}/{len(claims)} → {score:.2f}\")\n",
        "    return score\n",
        "\n",
        "\n",
        "# ── METRIC 2: ANSWER RELEVANCY ──────────────────────────────\n",
        "def _gen_questions(answer: str, n: int = 3) -> list:\n",
        "    prompt = f\"\"\"Đọc câu trả lời sau và sinh {n} câu hỏi mà câu trả lời này có thể trả lời được.\n",
        "\n",
        "Câu trả lời:\n",
        "{answer}\n",
        "\n",
        "Sinh {n} câu hỏi, mỗi câu bắt đầu bằng \"- \":\"\"\"\n",
        "    response = llm_call(prompt)\n",
        "    return [l.lstrip(\"- \").strip() for l in response.split(\"\\n\")\n",
        "            if l.strip().startswith(\"-\") and len(l.strip()) > 3][:n]\n",
        "\n",
        "\n",
        "def answer_relevancy(question: str, answer: str) -> float:\n",
        "    if not answer or not question:\n",
        "        return 0.0\n",
        "    gens = _gen_questions(answer, n=3)\n",
        "    if not gens:\n",
        "        emb = embed_model.encode([question, answer])\n",
        "        score = float(cosine_similarity([emb[0]], [emb[1]])[0][0])\n",
        "        print(f\"      Answer Relevancy (fallback embed): {score:.2f}\")\n",
        "        return max(0.0, min(1.0, score))\n",
        "    q_emb = embed_model.encode([question])\n",
        "    g_emb = embed_model.encode(gens)\n",
        "    score = float(cosine_similarity(q_emb, g_emb)[0].mean())\n",
        "    score = max(0.0, min(1.0, score))\n",
        "    print(f\"      Answer Relevancy: {score:.2f}\")\n",
        "    return score\n",
        "\n",
        "\n",
        "# ── METRIC 3: CONTEXT PRECISION ─────────────────────────────\n",
        "def _is_relevant(question: str, chunk: str, ground_truth: str) -> bool:\n",
        "    prompt = f\"\"\"Câu hỏi: {question}\n",
        "Đáp án mong đợi: {ground_truth}\n",
        "\n",
        "Đoạn context:\n",
        "{chunk[:1200]}\n",
        "\n",
        "Đoạn context này có chứa thông tin hữu ích để trả lời câu hỏi không?\n",
        "Trả lời CHỈ: YES hoặc NO\"\"\"\n",
        "    return \"YES\" in llm_call(prompt).upper()\n",
        "\n",
        "\n",
        "def context_precision(question: str, contexts: list, ground_truth: str) -> float:\n",
        "    if not contexts:\n",
        "        return 0.0\n",
        "    relevances = [_is_relevant(question, c, ground_truth) for c in contexts]\n",
        "    num, den, running = 0.0, 0.0, 0\n",
        "    for k, r in enumerate(relevances, 1):\n",
        "        if r:\n",
        "            running += 1\n",
        "            num += running / k\n",
        "            den += 1\n",
        "    score = (num / den) if den > 0 else 0.0\n",
        "    print(f\"      Context Precision: {sum(relevances)}/{len(contexts)} → {score:.2f}\")\n",
        "    return score\n",
        "\n",
        "\n",
        "# ── METRIC 4: CONTEXT RECALL ────────────────────────────────\n",
        "def _extract_statements(ground_truth: str) -> list:\n",
        "    prompt = f\"\"\"Phân tích đáp án chuẩn sau và liệt kê TẤT CẢ các thông tin/sự kiện cụ thể.\n",
        "\n",
        "Đáp án chuẩn:\n",
        "{ground_truth}\n",
        "\n",
        "Liệt kê các thông tin, mỗi thông tin bắt đầu bằng \"- \":\"\"\"\n",
        "    response = llm_call(prompt)\n",
        "    stmts = [l.lstrip(\"- \").strip() for l in response.split(\"\\n\")\n",
        "             if l.strip().startswith(\"-\") and len(l.strip()) > 2]\n",
        "    return stmts if stmts else [ground_truth]\n",
        "\n",
        "\n",
        "def _stmt_in_context(statement: str, context: str) -> bool:\n",
        "    prompt = f\"\"\"Context:\n",
        "{context[:2500]}\n",
        "\n",
        "Statement: {statement}\n",
        "\n",
        "Statement này có thể được suy ra từ context không?\n",
        "Trả lời CHỈ: YES hoặc NO\"\"\"\n",
        "    return \"YES\" in llm_call(prompt).upper()\n",
        "\n",
        "\n",
        "def context_recall(contexts: list, ground_truth: str) -> float:\n",
        "    if not contexts or not ground_truth:\n",
        "        return 0.0\n",
        "    ctx = \"\\n---\\n\".join(contexts)\n",
        "    stmts = _extract_statements(ground_truth)\n",
        "    supported = sum(_stmt_in_context(s, ctx) for s in stmts)\n",
        "    score = supported / len(stmts)\n",
        "    print(f\"      Context Recall: {supported}/{len(stmts)} → {score:.2f}\")\n",
        "    return score\n",
        "\n",
        "print(\"Các hàm RAGAS đã sẵn sàng\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3HmFs1xmCiO",
        "outputId": "c1756297-73f1-490e-a006-fa1456cd002d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Các hàm RAGAS đã sẵn sàng\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Slice samples\n",
        "eval_samples = samples[:LIMIT] if LIMIT else samples\n",
        "total = len(eval_samples)\n",
        "\n",
        "print(\"=\" * 65)\n",
        "print(f\" BẮT ĐẦU ĐÁNH GIÁ RAGAS — {total} SAMPLES\")\n",
        "print(f\"   Model judge : {OLLAMA_MODEL}\")\n",
        "print(f\"   Embed model : paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "print(\"=\" * 65)\n",
        "\n",
        "results = []\n",
        "t_start = time.time()\n",
        "\n",
        "for i, sample in enumerate(eval_samples, 1):\n",
        "    question     = sample[\"question\"]\n",
        "    answer       = sample[\"answer\"]\n",
        "    contexts     = sample[\"contexts\"]\n",
        "    ground_truth = sample[\"ground_truth\"]\n",
        "    qid          = sample.get(\"question_id\", str(i))\n",
        "\n",
        "    print(f\"\\n[{i:3}/{total}] {question[:60]}{'...' if len(question)>60 else ''}\")\n",
        "\n",
        "    if answer.startswith(\"ERROR:\") or not contexts:\n",
        "        print(\"        Bỏ qua (lỗi hoặc không có context)\")\n",
        "        results.append({\n",
        "            \"question_id\": qid, \"question\": question,\n",
        "            \"faithfulness\": None, \"answer_relevancy\": None,\n",
        "            \"context_precision\": None, \"context_recall\": None,\n",
        "            \"ragas_score\": None, \"error\": \"no_context_or_error\"\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    t0 = time.time()\n",
        "    f  = faithfulness(answer, contexts)\n",
        "    r  = answer_relevancy(question, answer)\n",
        "    p  = context_precision(question, contexts, ground_truth)\n",
        "    rc = context_recall(contexts, ground_truth)\n",
        "\n",
        "    ragas_avg = (f + r + p + rc) / 4\n",
        "    elapsed   = time.time() - t0\n",
        "\n",
        "    print(f\"       RAGAS: {ragas_avg:.3f}  [{elapsed:.0f}s]\")\n",
        "    results.append({\n",
        "        \"question_id\":       qid,\n",
        "        \"question\":          question,\n",
        "        \"ground_truth\":      ground_truth,\n",
        "        \"answer\":            answer,\n",
        "        \"num_contexts\":      len(contexts),\n",
        "        \"faithfulness\":      round(f,  4),\n",
        "        \"answer_relevancy\":  round(r,  4),\n",
        "        \"context_precision\": round(p,  4),\n",
        "        \"context_recall\":    round(rc, 4),\n",
        "        \"ragas_score\":       round(ragas_avg, 4),\n",
        "        \"error\":             None,\n",
        "    })\n",
        "\n",
        "    time.sleep(CALL_DELAY)\n",
        "\n",
        "total_time = time.time() - t_start\n",
        "\n",
        "valid   = [r for r in results if r[\"ragas_score\"] is not None]\n",
        "\n",
        "def avg(key):\n",
        "    # Exclude None values and 0.0 values from the overall average calculation\n",
        "    vals = [r[key] for r in valid if r[key] is not None and r[key] > 0]\n",
        "    return sum(vals) / len(vals) if vals else 0.0\n",
        "\n",
        "benchmarks = {\n",
        "    \"faithfulness\":      0.85,\n",
        "    \"answer_relevancy\":  0.85,\n",
        "    \"context_precision\": 0.75,\n",
        "    \"context_recall\":    0.80,\n",
        "}\n",
        "metrics = {k: avg(k) for k in benchmarks}\n",
        "metrics[\"ragas_score\"] = avg(\"ragas_score\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCDPZtiNmPgO",
        "outputId": "c6595a1c-9930-4bd5-ea76-b26ced7ae9ab",
        "collapsed": true
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            " BẮT ĐẦU ĐÁNH GIÁ RAGAS — 100 SAMPLES\n",
            "   Model judge : qwen2.5:7b\n",
            "   Embed model : paraphrase-multilingual-MiniLM-L12-v2\n",
            "=================================================================\n",
            "\n",
            "[  1/100] Nếu em từng bị cảnh cáo học vụ ở học kỳ trước nhưng học kỳ n...\n",
            "      Faithfulness: 1/4 → 0.25\n",
            "      Answer Relevancy: 0.75\n",
            "      Context Precision: 2/4 → 0.42\n",
            "      Context Recall: 1/7 → 0.14\n",
            "       RAGAS: 0.391  [25s]\n",
            "\n",
            "[  2/100] Sinh viên chưa đóng đủ học phí có được xét học bổng không, v...\n",
            "      Faithfulness: 8/9 → 0.89\n",
            "      Answer Relevancy: 0.92\n",
            "      Context Precision: 0/4 → 0.00\n",
            "      Context Recall: 4/8 → 0.50\n",
            "       RAGAS: 0.577  [25s]\n",
            "\n",
            "[  3/100] Cảnh cáo học vụ khác gì với cảnh cáo kỷ luật, và mỗi loại ản...\n",
            "      Faithfulness: 3/8 → 0.38\n",
            "      Answer Relevancy: 0.82\n",
            "      Context Precision: 2/4 → 1.00\n",
            "      Context Recall: 0/7 → 0.00\n",
            "       RAGAS: 0.549  [27s]\n",
            "\n",
            "[  4/100] Không tham gia hoạt động Đoàn – Hội thì điểm rèn luyện thấp ...\n",
            "      Faithfulness: 5/5 → 1.00\n",
            "      Answer Relevancy: 0.81\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 6/7 → 0.86\n",
            "       RAGAS: 0.917  [21s]\n",
            "\n",
            "[  5/100] Nếu còn nợ môn nhưng đã đủ GPA thì có được xét tốt nghiệp kh...\n",
            "      Faithfulness: 9/9 → 1.00\n",
            "      Answer Relevancy: 0.86\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 3/7 → 0.43\n",
            "       RAGAS: 0.822  [30s]\n",
            "\n",
            "[  6/100] Bị cảnh báo học tập do GPA thấp nhưng điểm rèn luyện cao thì...\n",
            "      Faithfulness: 3/11 → 0.27\n",
            "      Answer Relevancy: 0.74\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/9 → 0.33\n",
            "       RAGAS: 0.335  [30s]\n",
            "\n",
            "[  7/100] Học lại môn có phải đóng học phí riêng và có ảnh hưởng đến x...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.85\n",
            "      Context Precision: 0/4 → 0.00\n",
            "      Context Recall: 1/10 → 0.10\n",
            "       RAGAS: 0.300  [41s]\n",
            "\n",
            "[  8/100] Vi phạm nội quy KTX có ảnh hưởng đến kết quả học vụ hoặc học...\n",
            "      Faithfulness: 3/8 → 0.38\n",
            "      Answer Relevancy: 0.87\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/7 → 0.00\n",
            "       RAGAS: 0.312  [30s]\n",
            "\n",
            "[  9/100] Bị cảnh cáo học vụ có được đăng ký khóa luận tốt nghiệp khôn...\n",
            "      Faithfulness: 10/10 → 1.00\n",
            "      Answer Relevancy: 0.77\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/11 → 0.27\n",
            "       RAGAS: 0.510  [29s]\n",
            "\n",
            "[ 10/100] Sinh viên GPA cao nhưng điểm rèn luyện chỉ mức Trung bình th...\n",
            "      Faithfulness: 4/8 → 0.50\n",
            "      Answer Relevancy: 0.82\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/7 → 0.43\n",
            "       RAGAS: 0.436  [26s]\n",
            "\n",
            "[ 11/100] Nếu đang trong diện theo dõi học vụ nhưng chưa bị cảnh cáo t...\n",
            "      Faithfulness: 12/15 → 0.80\n",
            "      Answer Relevancy: 0.67\n",
            "      Context Precision: 1/2 → 0.50\n",
            "      Context Recall: 2/5 → 0.40\n",
            "       RAGAS: 0.593  [27s]\n",
            "\n",
            "[ 12/100] Học vượt tiến độ nhưng bị cảnh báo học tập thì có được xét t...\n",
            "      Faithfulness: 1/16 → 0.06\n",
            "      Answer Relevancy: 0.84\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/8 → 0.00\n",
            "       RAGAS: 0.225  [33s]\n",
            "\n",
            "[ 13/100] Sinh viên không vi phạm kỷ luật nhưng bị cảnh cáo học vụ thì...\n",
            "      Faithfulness: 8/10 → 0.80\n",
            "      Answer Relevancy: 0.81\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 1/7 → 0.14\n",
            "       RAGAS: 0.439  [29s]\n",
            "\n",
            "[ 14/100] Nếu nhận học bổng sau khi đã đóng học phí thì tiền được hoàn...\n",
            "      Faithfulness: 0/7 → 0.00\n",
            "      Answer Relevancy: 0.74\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 1/8 → 0.12\n",
            "       RAGAS: 0.216  [27s]\n",
            "\n",
            "[ 15/100] Bị cảnh cáo học vụ có bị buộc rời ký túc xá không?\n",
            "      Faithfulness: 4/6 → 0.67\n",
            "      Answer Relevancy: 0.69\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 2/7 → 0.29\n",
            "       RAGAS: 0.412  [26s]\n",
            "\n",
            "[ 16/100] Sinh viên học cải thiện điểm sau khi rớt môn thì kết quả đó ...\n",
            "      Faithfulness: 9/13 → 0.69\n",
            "      Answer Relevancy: 0.80\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 4/8 → 0.50\n",
            "       RAGAS: 0.498  [30s]\n",
            "\n",
            "[ 17/100] Còn nợ môn có được đi thực tập không, và kết quả thực tập có...\n",
            "      Faithfulness: 1/10 → 0.10\n",
            "      Answer Relevancy: 0.77\n",
            "      Context Precision: 0/4 → 0.00\n",
            "      Context Recall: 1/9 → 0.11\n",
            "       RAGAS: 0.246  [28s]\n",
            "\n",
            "[ 18/100] Sau khi bảo lưu quay lại học, kết quả cũ có được dùng xét họ...\n",
            "      Faithfulness: 5/6 → 0.83\n",
            "      Answer Relevancy: 0.88\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 1/5 → 0.20\n",
            "       RAGAS: 0.728  [21s]\n",
            "\n",
            "[ 19/100] Sinh viên hệ đại học chính quy có bắt buộc phải có IELTS mới...\n",
            "      Faithfulness: 7/13 → 0.54\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 1/5 → 0.20\n",
            "       RAGAS: 0.364  [36s]\n",
            "\n",
            "[ 20/100] Học bổng xét theo học kỳ hay theo năm học, và có xét tự động...\n",
            "      Faithfulness: 8/15 → 0.53\n",
            "      Answer Relevancy: 0.82\n",
            "      Context Precision: 0/4 → 0.00\n",
            "      Context Recall: 3/5 → 0.60\n",
            "       RAGAS: 0.488  [30s]\n",
            "\n",
            "[ 21/100] Nếu đang học song ngành và đồng thời không vi phạm nội quy t...\n",
            "      Faithfulness: 8/8 → 1.00\n",
            "      Answer Relevancy: 0.87\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 3/5 → 0.60\n",
            "       RAGAS: 0.867  [21s]\n",
            "\n",
            "[ 22/100] còn nợ 1 học phần bắt buộc có tác động đến đã hoàn thành học...\n",
            "      Faithfulness: 3/8 → 0.38\n",
            "      Answer Relevancy: 0.70\n",
            "      Context Precision: 0/4 → 0.00\n",
            "      Context Recall: 2/7 → 0.29\n",
            "       RAGAS: 0.339  [27s]\n",
            "\n",
            "[ 23/100] Trong trường hợp điểm rèn luyện dưới 65 nhưng vẫn được khoa ...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 1/6 → 0.17\n",
            "       RAGAS: 0.284  [29s]\n",
            "\n",
            "[ 24/100] bị kỷ luật mức khiển trách có làm mất quyền đã hoàn thành th...\n",
            "      Faithfulness: 9/10 → 0.90\n",
            "      Answer Relevancy: 0.81\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/8 → 0.38\n",
            "       RAGAS: 0.521  [27s]\n",
            "\n",
            "[ 25/100] Sinh viên đóng học phí trễ hạn nhưng có tham gia hoạt động p...\n",
            "      Faithfulness: 3/6 → 0.50\n",
            "      Answer Relevancy: 0.69\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/8 → 0.00\n",
            "       RAGAS: 0.297  [22s]\n",
            "\n",
            "[ 26/100] Nếu đang trong diện theo dõi học vụ và đồng thời đã bảo lưu ...\n",
            "      Faithfulness: 4/6 → 0.67\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/6 → 0.50\n",
            "       RAGAS: 0.472  [22s]\n",
            "\n",
            "[ 27/100] đã học cải thiện 2 môn có tác động đến muốn đăng ký khóa luậ...\n",
            "      Faithfulness: 6/9 → 0.67\n",
            "      Answer Relevancy: 0.56\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/9 → 0.00\n",
            "       RAGAS: 0.306  [38s]\n",
            "\n",
            "[ 28/100] Trong trường hợp muốn xét tốt nghiệp sớm nhưng vẫn đã học vư...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.86\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/5 → 0.00\n",
            "       RAGAS: 0.276  [22s]\n",
            "\n",
            "[ 29/100] đăng ký thiếu tín chỉ tối thiểu có làm mất quyền đạt chuẩn đ...\n",
            "      Faithfulness: 1/12 → 0.08\n",
            "      Answer Relevancy: 0.80\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/10 → 0.00\n",
            "       RAGAS: 0.222  [40s]\n",
            "\n",
            "[ 30/100] Sinh viên bị cảnh báo học tập 1 lần nhưng GPA đạt loại Giỏi ...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.89\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 1/7 → 0.14\n",
            "       RAGAS: 0.322  [24s]\n",
            "\n",
            "[ 31/100] Nếu đang học song ngành và đồng thời không vi phạm nội quy t...\n",
            "      Faithfulness: 10/11 → 0.91\n",
            "      Answer Relevancy: 0.76\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 3/5 → 0.60\n",
            "       RAGAS: 0.818  [25s]\n",
            "\n",
            "[ 32/100] còn nợ 1 học phần bắt buộc có tác động đến đã hoàn thành học...\n",
            "      Faithfulness: 3/8 → 0.38\n",
            "      Answer Relevancy: 0.70\n",
            "      Context Precision: 0/4 → 0.00\n",
            "      Context Recall: 2/7 → 0.29\n",
            "       RAGAS: 0.339  [25s]\n",
            "\n",
            "[ 33/100] Trong trường hợp điểm rèn luyện dưới 65 nhưng vẫn được khoa ...\n",
            "      Faithfulness: 1/7 → 0.14\n",
            "      Answer Relevancy: 0.80\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 1/6 → 0.17\n",
            "       RAGAS: 0.278  [27s]\n",
            "\n",
            "[ 34/100] bị kỷ luật mức khiển trách có làm mất quyền đã hoàn thành th...\n",
            "      Faithfulness: 9/10 → 0.90\n",
            "      Answer Relevancy: 0.81\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/8 → 0.38\n",
            "       RAGAS: 0.521  [26s]\n",
            "\n",
            "[ 35/100] Sinh viên đóng học phí trễ hạn nhưng có tham gia hoạt động p...\n",
            "      Faithfulness: 3/6 → 0.50\n",
            "      Answer Relevancy: 0.69\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/8 → 0.00\n",
            "       RAGAS: 0.297  [23s]\n",
            "\n",
            "[ 36/100] Nếu đang trong diện theo dõi học vụ và đồng thời đã bảo lưu ...\n",
            "      Faithfulness: 4/6 → 0.67\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/6 → 0.50\n",
            "       RAGAS: 0.472  [22s]\n",
            "\n",
            "[ 37/100] đã học cải thiện 2 môn có tác động đến muốn đăng ký khóa luậ...\n",
            "      Faithfulness: 6/9 → 0.67\n",
            "      Answer Relevancy: 0.56\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/9 → 0.00\n",
            "       RAGAS: 0.306  [38s]\n",
            "\n",
            "[ 38/100] Trong trường hợp muốn xét tốt nghiệp sớm nhưng vẫn đã học vư...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.86\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/5 → 0.00\n",
            "       RAGAS: 0.276  [23s]\n",
            "\n",
            "[ 39/100] đăng ký thiếu tín chỉ tối thiểu có làm mất quyền đạt chuẩn đ...\n",
            "      Faithfulness: 1/12 → 0.08\n",
            "      Answer Relevancy: 0.80\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/10 → 0.00\n",
            "       RAGAS: 0.222  [41s]\n",
            "\n",
            "[ 40/100] Sinh viên bị cảnh báo học tập 1 lần nhưng GPA đạt loại Giỏi ...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.89\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 1/7 → 0.14\n",
            "       RAGAS: 0.322  [24s]\n",
            "\n",
            "[ 41/100] Nếu đang học song ngành và đồng thời không vi phạm nội quy t...\n",
            "      Faithfulness: 10/11 → 0.91\n",
            "      Answer Relevancy: 0.76\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 3/5 → 0.60\n",
            "       RAGAS: 0.818  [25s]\n",
            "\n",
            "[ 42/100] còn nợ 1 học phần bắt buộc có tác động đến đã hoàn thành học...\n",
            "      Faithfulness: 3/8 → 0.38\n",
            "      Answer Relevancy: 0.70\n",
            "      Context Precision: 0/4 → 0.00\n",
            "      Context Recall: 2/7 → 0.29\n",
            "       RAGAS: 0.339  [26s]\n",
            "\n",
            "[ 43/100] Trong trường hợp điểm rèn luyện dưới 65 nhưng vẫn được khoa ...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 1/6 → 0.17\n",
            "       RAGAS: 0.284  [29s]\n",
            "\n",
            "[ 44/100] bị kỷ luật mức khiển trách có làm mất quyền đã hoàn thành th...\n",
            "      Faithfulness: 9/10 → 0.90\n",
            "      Answer Relevancy: 0.81\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/8 → 0.38\n",
            "       RAGAS: 0.521  [26s]\n",
            "\n",
            "[ 45/100] Sinh viên đóng học phí trễ hạn nhưng có tham gia hoạt động p...\n",
            "      Faithfulness: 3/6 → 0.50\n",
            "      Answer Relevancy: 0.69\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/8 → 0.00\n",
            "       RAGAS: 0.297  [22s]\n",
            "\n",
            "[ 46/100] Nếu đang trong diện theo dõi học vụ và đồng thời đã bảo lưu ...\n",
            "      Faithfulness: 4/6 → 0.67\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/6 → 0.50\n",
            "       RAGAS: 0.472  [23s]\n",
            "\n",
            "[ 47/100] đã học cải thiện 2 môn có tác động đến muốn đăng ký khóa luậ...\n",
            "      Faithfulness: 6/9 → 0.67\n",
            "      Answer Relevancy: 0.56\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/9 → 0.00\n",
            "       RAGAS: 0.306  [38s]\n",
            "\n",
            "[ 48/100] Trong trường hợp muốn xét tốt nghiệp sớm nhưng vẫn đã học vư...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.86\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/5 → 0.00\n",
            "       RAGAS: 0.276  [22s]\n",
            "\n",
            "[ 49/100] đăng ký thiếu tín chỉ tối thiểu có làm mất quyền đạt chuẩn đ...\n",
            "      Faithfulness: 1/12 → 0.08\n",
            "      Answer Relevancy: 0.80\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/10 → 0.00\n",
            "       RAGAS: 0.222  [41s]\n",
            "\n",
            "[ 50/100] Sinh viên bị cảnh báo học tập 1 lần nhưng GPA đạt loại Giỏi ...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.89\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 1/7 → 0.14\n",
            "       RAGAS: 0.322  [26s]\n",
            "\n",
            "[ 51/100] Nếu đang học song ngành và đồng thời không vi phạm nội quy t...\n",
            "      Faithfulness: 10/11 → 0.91\n",
            "      Answer Relevancy: 0.76\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 3/5 → 0.60\n",
            "       RAGAS: 0.818  [26s]\n",
            "\n",
            "[ 52/100] còn nợ 1 học phần bắt buộc có tác động đến đã hoàn thành học...\n",
            "      Faithfulness: 3/8 → 0.38\n",
            "      Answer Relevancy: 0.70\n",
            "      Context Precision: 0/4 → 0.00\n",
            "      Context Recall: 2/7 → 0.29\n",
            "       RAGAS: 0.339  [28s]\n",
            "\n",
            "[ 53/100] Trong trường hợp điểm rèn luyện dưới 65 nhưng vẫn được khoa ...\n",
            "      Faithfulness: 2/7 → 0.29\n",
            "      Answer Relevancy: 0.74\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 1/6 → 0.17\n",
            "       RAGAS: 0.298  [26s]\n",
            "\n",
            "[ 54/100] bị kỷ luật mức khiển trách có làm mất quyền đã hoàn thành th...\n",
            "      Faithfulness: 9/10 → 0.90\n",
            "      Answer Relevancy: 0.81\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/8 → 0.38\n",
            "       RAGAS: 0.521  [28s]\n",
            "\n",
            "[ 55/100] Sinh viên đóng học phí trễ hạn nhưng có tham gia hoạt động p...\n",
            "      Faithfulness: 3/6 → 0.50\n",
            "      Answer Relevancy: 0.69\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/8 → 0.00\n",
            "       RAGAS: 0.297  [22s]\n",
            "\n",
            "[ 56/100] Nếu đang trong diện theo dõi học vụ và đồng thời đã bảo lưu ...\n",
            "      Faithfulness: 4/6 → 0.67\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/6 → 0.50\n",
            "       RAGAS: 0.472  [22s]\n",
            "\n",
            "[ 57/100] đã học cải thiện 2 môn có tác động đến muốn đăng ký khóa luậ...\n",
            "      Faithfulness: 7/12 → 0.58\n",
            "      Answer Relevancy: 0.59\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/9 → 0.00\n",
            "       RAGAS: 0.293  [41s]\n",
            "\n",
            "[ 58/100] Trong trường hợp muốn xét tốt nghiệp sớm nhưng vẫn đã học vư...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.86\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/5 → 0.00\n",
            "       RAGAS: 0.276  [23s]\n",
            "\n",
            "[ 59/100] đăng ký thiếu tín chỉ tối thiểu có làm mất quyền đạt chuẩn đ...\n",
            "      Faithfulness: 1/14 → 0.07\n",
            "      Answer Relevancy: 0.76\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/10 → 0.00\n",
            "       RAGAS: 0.208  [38s]\n",
            "\n",
            "[ 60/100] Sinh viên bị cảnh báo học tập 1 lần nhưng GPA đạt loại Giỏi ...\n",
            "      Faithfulness: 0/7 → 0.00\n",
            "      Answer Relevancy: 0.88\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 1/7 → 0.14\n",
            "       RAGAS: 0.507  [22s]\n",
            "\n",
            "[ 61/100] Nếu đang học song ngành và đồng thời không vi phạm nội quy t...\n",
            "      Faithfulness: 10/11 → 0.91\n",
            "      Answer Relevancy: 0.76\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 3/5 → 0.60\n",
            "       RAGAS: 0.818  [26s]\n",
            "\n",
            "[ 62/100] còn nợ 1 học phần bắt buộc có tác động đến đã hoàn thành học...\n",
            "      Faithfulness: 3/8 → 0.38\n",
            "      Answer Relevancy: 0.70\n",
            "      Context Precision: 0/4 → 0.00\n",
            "      Context Recall: 2/7 → 0.29\n",
            "       RAGAS: 0.339  [27s]\n",
            "\n",
            "[ 63/100] Trong trường hợp điểm rèn luyện dưới 65 nhưng vẫn được khoa ...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 1/6 → 0.17\n",
            "       RAGAS: 0.284  [29s]\n",
            "\n",
            "[ 64/100] bị kỷ luật mức khiển trách có làm mất quyền đã hoàn thành th...\n",
            "      Faithfulness: 9/10 → 0.90\n",
            "      Answer Relevancy: 0.81\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/8 → 0.38\n",
            "       RAGAS: 0.521  [27s]\n",
            "\n",
            "[ 65/100] Sinh viên đóng học phí trễ hạn nhưng có tham gia hoạt động p...\n",
            "      Faithfulness: 3/6 → 0.50\n",
            "      Answer Relevancy: 0.69\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/8 → 0.00\n",
            "       RAGAS: 0.297  [22s]\n",
            "\n",
            "[ 66/100] Nếu đang trong diện theo dõi học vụ và đồng thời đã bảo lưu ...\n",
            "      Faithfulness: 4/6 → 0.67\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/6 → 0.50\n",
            "       RAGAS: 0.472  [22s]\n",
            "\n",
            "[ 67/100] đã học cải thiện 2 môn có tác động đến muốn đăng ký khóa luậ...\n",
            "      Faithfulness: 6/9 → 0.67\n",
            "      Answer Relevancy: 0.56\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/9 → 0.00\n",
            "       RAGAS: 0.306  [38s]\n",
            "\n",
            "[ 68/100] Trong trường hợp muốn xét tốt nghiệp sớm nhưng vẫn đã học vư...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.86\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/5 → 0.00\n",
            "       RAGAS: 0.276  [22s]\n",
            "\n",
            "[ 69/100] đăng ký thiếu tín chỉ tối thiểu có làm mất quyền đạt chuẩn đ...\n",
            "      Faithfulness: 1/12 → 0.08\n",
            "      Answer Relevancy: 0.80\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/10 → 0.00\n",
            "       RAGAS: 0.222  [40s]\n",
            "\n",
            "[ 70/100] Sinh viên bị cảnh báo học tập 1 lần nhưng GPA đạt loại Giỏi ...\n",
            "      Faithfulness: 0/7 → 0.00\n",
            "      Answer Relevancy: 0.88\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 1/7 → 0.14\n",
            "       RAGAS: 0.507  [22s]\n",
            "\n",
            "[ 71/100] Nếu đang học song ngành và đồng thời không vi phạm nội quy t...\n",
            "      Faithfulness: 10/11 → 0.91\n",
            "      Answer Relevancy: 0.76\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 3/5 → 0.60\n",
            "       RAGAS: 0.818  [26s]\n",
            "\n",
            "[ 72/100] còn nợ 1 học phần bắt buộc có tác động đến đã hoàn thành học...\n",
            "      Faithfulness: 3/8 → 0.38\n",
            "      Answer Relevancy: 0.70\n",
            "      Context Precision: 0/4 → 0.00\n",
            "      Context Recall: 2/7 → 0.29\n",
            "       RAGAS: 0.339  [26s]\n",
            "\n",
            "[ 73/100] Trong trường hợp điểm rèn luyện dưới 65 nhưng vẫn được khoa ...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 1/6 → 0.17\n",
            "       RAGAS: 0.284  [29s]\n",
            "\n",
            "[ 74/100] bị kỷ luật mức khiển trách có làm mất quyền đã hoàn thành th...\n",
            "      Faithfulness: 9/10 → 0.90\n",
            "      Answer Relevancy: 0.81\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/8 → 0.38\n",
            "       RAGAS: 0.521  [26s]\n",
            "\n",
            "[ 75/100] Sinh viên đóng học phí trễ hạn nhưng có tham gia hoạt động p...\n",
            "      Faithfulness: 3/6 → 0.50\n",
            "      Answer Relevancy: 0.69\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/8 → 0.00\n",
            "       RAGAS: 0.297  [22s]\n",
            "\n",
            "[ 76/100] Nếu đang trong diện theo dõi học vụ và đồng thời đã bảo lưu ...\n",
            "      Faithfulness: 4/6 → 0.67\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/6 → 0.50\n",
            "       RAGAS: 0.472  [22s]\n",
            "\n",
            "[ 77/100] đã học cải thiện 2 môn có tác động đến muốn đăng ký khóa luậ...\n",
            "      Faithfulness: 6/9 → 0.67\n",
            "      Answer Relevancy: 0.56\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/9 → 0.00\n",
            "       RAGAS: 0.306  [38s]\n",
            "\n",
            "[ 78/100] Trong trường hợp muốn xét tốt nghiệp sớm nhưng vẫn đã học vư...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.85\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/5 → 0.00\n",
            "       RAGAS: 0.276  [24s]\n",
            "\n",
            "[ 79/100] đăng ký thiếu tín chỉ tối thiểu có làm mất quyền đạt chuẩn đ...\n",
            "      Faithfulness: 1/12 → 0.08\n",
            "      Answer Relevancy: 0.80\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/10 → 0.00\n",
            "       RAGAS: 0.222  [41s]\n",
            "\n",
            "[ 80/100] Sinh viên bị cảnh báo học tập 1 lần nhưng GPA đạt loại Giỏi ...\n",
            "      Faithfulness: 0/7 → 0.00\n",
            "      Answer Relevancy: 0.88\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 1/7 → 0.14\n",
            "       RAGAS: 0.507  [22s]\n",
            "\n",
            "[ 81/100] Nếu đang học song ngành và đồng thời không vi phạm nội quy t...\n",
            "      Faithfulness: 9/11 → 0.82\n",
            "      Answer Relevancy: 0.84\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 3/5 → 0.60\n",
            "       RAGAS: 0.813  [26s]\n",
            "\n",
            "[ 82/100] còn nợ 1 học phần bắt buộc có tác động đến đã hoàn thành học...\n",
            "      Faithfulness: 3/8 → 0.38\n",
            "      Answer Relevancy: 0.70\n",
            "      Context Precision: 0/4 → 0.00\n",
            "      Context Recall: 2/7 → 0.29\n",
            "       RAGAS: 0.339  [26s]\n",
            "\n",
            "[ 83/100] Trong trường hợp điểm rèn luyện dưới 65 nhưng vẫn được khoa ...\n",
            "      Faithfulness: 1/7 → 0.14\n",
            "      Answer Relevancy: 0.74\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 1/6 → 0.17\n",
            "       RAGAS: 0.262  [28s]\n",
            "\n",
            "[ 84/100] bị kỷ luật mức khiển trách có làm mất quyền đã hoàn thành th...\n",
            "      Faithfulness: 9/10 → 0.90\n",
            "      Answer Relevancy: 0.81\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/8 → 0.38\n",
            "       RAGAS: 0.521  [26s]\n",
            "\n",
            "[ 85/100] Sinh viên đóng học phí trễ hạn nhưng có tham gia hoạt động p...\n",
            "      Faithfulness: 1/12 → 0.08\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/8 → 0.00\n",
            "       RAGAS: 0.202  [28s]\n",
            "\n",
            "[ 86/100] Nếu đang trong diện theo dõi học vụ và đồng thời đã bảo lưu ...\n",
            "      Faithfulness: 4/6 → 0.67\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/6 → 0.50\n",
            "       RAGAS: 0.472  [22s]\n",
            "\n",
            "[ 87/100] đã học cải thiện 2 môn có tác động đến muốn đăng ký khóa luậ...\n",
            "      Faithfulness: 7/12 → 0.58\n",
            "      Answer Relevancy: 0.59\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/9 → 0.00\n",
            "       RAGAS: 0.293  [40s]\n",
            "\n",
            "[ 88/100] Trong trường hợp muốn xét tốt nghiệp sớm nhưng vẫn đã học vư...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.85\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/5 → 0.00\n",
            "       RAGAS: 0.276  [24s]\n",
            "\n",
            "[ 89/100] đăng ký thiếu tín chỉ tối thiểu có làm mất quyền đạt chuẩn đ...\n",
            "      Faithfulness: 1/12 → 0.08\n",
            "      Answer Relevancy: 0.80\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/10 → 0.00\n",
            "       RAGAS: 0.222  [40s]\n",
            "\n",
            "[ 90/100] Sinh viên bị cảnh báo học tập 1 lần nhưng GPA đạt loại Giỏi ...\n",
            "      Faithfulness: 0/7 → 0.00\n",
            "      Answer Relevancy: 0.88\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 1/7 → 0.14\n",
            "       RAGAS: 0.507  [22s]\n",
            "\n",
            "[ 91/100] Nếu đang học song ngành và đồng thời không vi phạm nội quy t...\n",
            "      Faithfulness: 9/11 → 0.82\n",
            "      Answer Relevancy: 0.84\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 3/5 → 0.60\n",
            "       RAGAS: 0.813  [26s]\n",
            "\n",
            "[ 92/100] còn nợ 1 học phần bắt buộc có tác động đến đã hoàn thành học...\n",
            "      Faithfulness: 3/8 → 0.38\n",
            "      Answer Relevancy: 0.70\n",
            "      Context Precision: 0/4 → 0.00\n",
            "      Context Recall: 2/7 → 0.29\n",
            "       RAGAS: 0.339  [26s]\n",
            "\n",
            "[ 93/100] Trong trường hợp điểm rèn luyện dưới 65 nhưng vẫn được khoa ...\n",
            "      Faithfulness: 2/8 → 0.25\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 1/6 → 0.17\n",
            "       RAGAS: 0.284  [29s]\n",
            "\n",
            "[ 94/100] bị kỷ luật mức khiển trách có làm mất quyền đã hoàn thành th...\n",
            "      Faithfulness: 9/10 → 0.90\n",
            "      Answer Relevancy: 0.81\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/8 → 0.38\n",
            "       RAGAS: 0.521  [26s]\n",
            "\n",
            "[ 95/100] Sinh viên đóng học phí trễ hạn nhưng có tham gia hoạt động p...\n",
            "      Faithfulness: 1/10 → 0.10\n",
            "      Answer Relevancy: 0.73\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/8 → 0.00\n",
            "       RAGAS: 0.208  [27s]\n",
            "\n",
            "[ 96/100] Nếu đang trong diện theo dõi học vụ và đồng thời đã bảo lưu ...\n",
            "      Faithfulness: 4/6 → 0.67\n",
            "      Answer Relevancy: 0.72\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 3/6 → 0.50\n",
            "       RAGAS: 0.472  [23s]\n",
            "\n",
            "[ 97/100] đã học cải thiện 2 môn có tác động đến muốn đăng ký khóa luậ...\n",
            "      Faithfulness: 7/12 → 0.58\n",
            "      Answer Relevancy: 0.59\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/9 → 0.00\n",
            "       RAGAS: 0.293  [39s]\n",
            "\n",
            "[ 98/100] Trong trường hợp muốn xét tốt nghiệp sớm nhưng vẫn đã học vư...\n",
            "      Faithfulness: 3/10 → 0.30\n",
            "      Answer Relevancy: 0.86\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/5 → 0.00\n",
            "       RAGAS: 0.289  [26s]\n",
            "\n",
            "[ 99/100] đăng ký thiếu tín chỉ tối thiểu có làm mất quyền đạt chuẩn đ...\n",
            "      Faithfulness: 1/12 → 0.08\n",
            "      Answer Relevancy: 0.80\n",
            "      Context Precision: 0/2 → 0.00\n",
            "      Context Recall: 0/10 → 0.00\n",
            "       RAGAS: 0.222  [40s]\n",
            "\n",
            "[100/100] Sinh viên bị cảnh báo học tập 1 lần nhưng GPA đạt loại Giỏi ...\n",
            "      Faithfulness: 0/7 → 0.00\n",
            "      Answer Relevancy: 0.88\n",
            "      Context Precision: 2/2 → 1.00\n",
            "      Context Recall: 1/7 → 0.14\n",
            "       RAGAS: 0.507  [22s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\" * 65)\n",
        "print(\"KẾT QUẢ RAGAS\")\n",
        "print(\"=\" * 65)\n",
        "print(f\"{'Metric':<22} {'Score':>7}\")\n",
        "print(\"─\" * 30)\n",
        "\n",
        "for key in [\"faithfulness\", \"answer_relevancy\", \"context_precision\", \"context_recall\"]:\n",
        "    score = metrics[key]\n",
        "    print(f\"{key.replace('_',' ').title():<22} {score:>7.4f}\")\n",
        "\n",
        "# Calculate RAGAS Average as the average of the four metrics\n",
        "ragas_overall_avg = (metrics[\"faithfulness\"] + metrics[\"answer_relevancy\"] + metrics[\"context_precision\"] + metrics[\"context_recall\"]) / 4\n",
        "\n",
        "print(\"─\" * 30)\n",
        "print(f\"{'RAGAS Average':<22} {ragas_overall_avg:>7.4f}\")\n",
        "print(f\"\\n  Samples  : {len(valid)}/{total} hợp lệ\")\n",
        "print(f\"  Thời gian: {total_time/60:.1f} phút\")\n",
        "print(f\"  Model    : {OLLAMA_MODEL}\")\n",
        "print(\"=\" * 65)\n",
        "\n",
        "# Xuất Excel\n",
        "df        = pd.DataFrame(results)\n",
        "ts        = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "xlsx_path = f\"{OUTPUT_DIR}/ragas_report_{ts}.xlsx\"\n",
        "df.to_excel(xlsx_path, index=False)\n",
        "print(f\"\\nBáo cáo Excel: {xlsx_path}\")\n",
        "\n",
        "# Xuất JSON summary\n",
        "import json\n",
        "summary = {\n",
        "    \"evaluated_at\":  datetime.now().isoformat(),\n",
        "    \"model_judge\":   OLLAMA_MODEL,\n",
        "    \"total_samples\": total,\n",
        "    \"valid_samples\": len(valid),\n",
        "    \"metrics\":       {k: round(v, 4) for k, v in metrics.items()},\n",
        "    \"total_time_min\": round(total_time / 60, 1),\n",
        "}\n",
        "# Update the ragas_score in the summary with the newly calculated overall average\n",
        "summary[\"metrics\"][\"ragas_score\"] = round(ragas_overall_avg, 4)\n",
        "\n",
        "json_path = f\"{OUTPUT_DIR}/ragas_summary_{ts}.json\"\n",
        "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
        "print(f\"Summary JSON : {json_path}\")\n",
        "\n",
        "\n",
        "from google.colab import files as colab_files\n",
        "\n",
        "print(\"Đang tải file về máy...\")\n",
        "colab_files.download(xlsx_path)\n",
        "colab_files.download(json_path)\n",
        "print(\"Đã download!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "vl-fuMXBmHJ5",
        "outputId": "0d34e098-cc6a-42ea-9cc5-f6470d42f005"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=================================================================\n",
            "KẾT QUẢ RAGAS\n",
            "=================================================================\n",
            "Metric                   Score\n",
            "──────────────────────────────\n",
            "Faithfulness            0.5021\n",
            "Answer Relevancy        0.7642\n",
            "Context Precision       0.9430\n",
            "Context Recall          0.3414\n",
            "──────────────────────────────\n",
            "RAGAS Average           0.6377\n",
            "\n",
            "  Samples  : 100/100 hợp lệ\n",
            "  Thời gian: 46.9 phút\n",
            "  Model    : qwen2.5:7b\n",
            "=================================================================\n",
            "\n",
            "Báo cáo Excel: /content/drive/MyDrive/KLTN/ragas_output/ragas_report_20260221_112759.xlsx\n",
            "Summary JSON : /content/drive/MyDrive/KLTN/ragas_output/ragas_summary_20260221_112759.json\n",
            "Đang tải file về máy...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_25c9bf66-ffc1-4638-9aa4-147d69d73a2f\", \"ragas_report_20260221_112759.xlsx\", 53551)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_002fa0e9-f1b8-4b92-b3b7-f0aa5018f33f\", \"ragas_summary_20260221_112759.json\", 323)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã download!\n"
          ]
        }
      ]
    }
  ]
}